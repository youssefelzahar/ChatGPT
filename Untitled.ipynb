{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e23d63c-ab1d-4425-8ff8-0b674e2a1e19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4832b291-564b-4188-9253-29ee84be38d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80a16d85-ad42-4901-85c2-3f75df96dd3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_train_dataset=load_dataset(\"Helsinki-NLP/opus-100\",\"en-ms\",split='train')\n",
    "raw_validate_dataset=load_dataset(\"Helsinki-NLP/opus-100\",\"en-ms\",split='validation')\n",
    "raw_test_dataset=load_dataset(\"Helsinki-NLP/opus-100\",\"en-ms\",split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed326848-d4c5-4d48-b432-ab4a4762ddd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "dataset_en = []     \n",
    "dataset_my = []\n",
    "file_count = 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2964c6db-65d2-44f7-bf82-06d8aa3a9a38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [00:00<00:00, 2129062.39it/s]\n"
     ]
    }
   ],
   "source": [
    "for data in tqdm(raw_train_dataset[\"translation\"]):\n",
    "    dataset_en.append(data[\"en\"].replace('\\n',\" \"))\n",
    "    dataset_my.append(data[\"ms\"].replace('\\n',\" \"))\n",
    "    if len(dataset_en)==50000:\n",
    "        with open(f'./dataset-en/file{file_count}.txt', 'w', encoding='utf-8') as fp:\n",
    "            fp.write('\\n'.join(dataset_en))\n",
    "            dataset_en\n",
    "        with open(f'./dataset-my/file{file_count}.txt', 'w', encoding='utf-8') as fp:\n",
    "            fp.write('\\n'.join(dataset_my))\n",
    "            dataset_my = []\n",
    "        file_count += 1    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a68b6f1e-dfef-4b7b-9fab-bfdcba14f574",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_en=[str(file) for file in Path('./dataset-en').glob(\"**/*.txt\")]\n",
    "path_my=[str(file) for file in Path('./dataset-my').glob(\"**/*.txt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fc7a7ca-849a-408a-8e18-f7868f6ddd7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "toknizer_en=Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "#Additional special tokens are created such as [UNK] - to represent Unknown words, [PAD] - Padding token to maintain same sequence length across the model.\n",
    "# [CLS] - token to denote start of sentence, [SEP] - token to denote end of sentence.\n",
    "trainer_en=BpeTrainer(min_frequency=2,special_tokens=[\"[PAD]\",\"[UNK]\",\"[CLS]\",\"[SEP]\",\"[MASK]\"])\n",
    "toknizer_en.pre_tokenizer=Whitespace()\n",
    "toknizer_en.train(files=path_en,trainer=trainer_en)\n",
    "toknizer_en.save(\"./tokenizer_en/tokenizer_en.json\")\n",
    "\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b39e35e1-7eae-46ef-bf46-7010a38d120a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "toknizer_my=Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "trainer_my=BpeTrainer(min_frequency=2,special_tokens=[\"[PAD]\",\"[UNK]\",\"[CLS]\",\"[SEP]\",\"[MASK]\"])\n",
    "toknizer_my.pre_tokenizer=Whitespace()\n",
    "toknizer_my.train(files=path_my,trainer=trainer_my)\n",
    "toknizer_my.save(\"./tokenizer_my/tokenizer_my.json\")\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a0d5f86-03a8-4501-af7c-7df9e3a1e641",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "toknizer_en=Tokenizer.from_file(\"./tokenizer_en/tokenizer_en.json\")\n",
    "toknizer_my=Tokenizer.from_file(\"./tokenizer_my/tokenizer_my.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a7a046e-ab8b-4260-ae01-a69b29d7682b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_vocab_size=toknizer_en.get_vocab_size()\n",
    "target_vocab_ize=toknizer_my.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8390a5e-1e1e-4149-9c2c-4b7adecf4cb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CLS_ID = torch.tensor([toknizer_my.token_to_id(\"[CLS]\")], dtype=torch.int64).to(device)\n",
    "SEP_ID = torch.tensor([toknizer_my.token_to_id(\"[SEP]\")], dtype=torch.int64).to(device)\n",
    "PAD_ID = torch.tensor([toknizer_my.token_to_id(\"[PAD]\")], dtype=torch.int64).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d36ccc2-e483-4d03-8126-07350f63b6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seqlen_source: 1358\n",
      "max_seqlen_target: 563\n"
     ]
    }
   ],
   "source": [
    "# This class takes raw dataset and max_seq_len (maximum length of a sequence in the entire dataset).\n",
    "class EncodeDataset(Dataset):\n",
    "    def __init__(self, raw_dataset, max_seq_len):\n",
    "        super().__init__()\n",
    "        self.raw_dataset = raw_dataset\n",
    "        self.max_seq_len = max_seq_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.raw_dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # Fetching raw text for the given index that consists of source and target pair.\n",
    "        raw_text = self.raw_dataset[index]\n",
    "        \n",
    "        # Separating text to source and target text and will be later used for encoding.\n",
    "        source_text = raw_text[\"en\"]\n",
    "        target_text = raw_text[\"ms\"]\n",
    "\n",
    "        # Encoding source text with source tokenizer(tokenizer_en) and target text with target tokenizer(tokenizer_my).\n",
    "        source_text_encoded = torch.tensor(toknizer_en.encode(source_text).ids, dtype = torch.int64).to(device)    \n",
    "        target_text_encoded = torch.tensor(toknizer_my.encode(target_text).ids, dtype = torch.int64).to(device)\n",
    "\n",
    "        # To train the model, the sequence lenth of each input sequence should be equal max seq length. \n",
    "        # Hence additional number of padding will be added to the input sequence if the length is less than the max_seq_len.\n",
    "        num_source_padding = self.max_seq_len - len(source_text_encoded) - 2 \n",
    "        num_target_padding = self.max_seq_len - len(target_text_encoded) - 1 \n",
    "\n",
    "        encoder_padding = torch.tensor([PAD_ID] * num_source_padding, dtype = torch.int64).to(device)\n",
    "        decoder_padding = torch.tensor([PAD_ID] * num_target_padding, dtype = torch.int64).to(device)\n",
    "        \n",
    "        # encoder_input has the first token as start of sentence - CLS_ID, followed by source encoding which is then followed by the end of sentence token - SEP.\n",
    "        # To reach the required max_seq_len, addition PAD token will be added at the end.        \n",
    "        encoder_input = torch.cat([CLS_ID, source_text_encoded, SEP_ID, encoder_padding]).to(device)    \n",
    "\n",
    "        # decoder_input has the first token as start of sentence - CLS_ID, followed by target encoding.\n",
    "        # To reach the required max_seq_len, addition PAD token will be added at the end. There is no end of sentence token - SEP in decoder_input.\n",
    "        decoder_input = torch.cat([CLS_ID, target_text_encoded, decoder_padding ]).to(device)           \n",
    "        \n",
    "        # target_label has the first token as target encoding followed by end of sentence token - SEP. There is no start of sentence token - CLS in target label.\n",
    "        # To reach the required max_seq_len, addition PAD token will be added at the end. \n",
    "        target_label = torch.cat([target_text_encoded,SEP_ID,decoder_padding]).to(device)               \n",
    "        \n",
    "        # As we've added extra padding token with input encoding, during training, we don't want this token to be trained by model as there is nothing to learn in this token.\n",
    "        # So, we'll use encoder mask to nullify the padding token value prior to calculating output of self attention in encoder block.\n",
    "        encoder_mask = (encoder_input != PAD_ID).unsqueeze(0).unsqueeze(0).int().to(device)             \n",
    "        \n",
    "        # We also don't want any token to get influenced by the future token during the decoding stage. Hence, Causal mask is being implemented during masked multihead attention to handle this. \n",
    "        decoder_mask = (decoder_input != PAD_ID).unsqueeze(0).unsqueeze(0).int() & causal_mask(decoder_input.size(0)).to(device) \n",
    "\n",
    "        return {\n",
    "            'encoder_input': encoder_input,\n",
    "            'decoder_input': decoder_input,\n",
    "            'target_label': target_label,\n",
    "            'encoder_mask': encoder_mask,\n",
    "            'decoder_mask': decoder_mask,\n",
    "            'source_text': source_text,\n",
    "            'target_text': target_text\n",
    "        }\n",
    "\n",
    "# Causal mask will make sure any token that comes after the current token will be masked, meaning the value will be replaced by -ve infinity which will be converted to zero or close to zero after softmax function. \n",
    "# Hence the model will just ignore these value or willn't be able to learn anything from these values.\n",
    "def causal_mask(size):\n",
    "  # dimension of causal mask (batch_size, seq_len, seq_len)\n",
    "  mask = torch.triu(torch.ones(1, size, size), diagonal = 1).type(torch.int)\n",
    "  return mask == 0\n",
    "\n",
    "# To calculate the max sequence lenth in the entire training dataset for the source and target dataset.\n",
    "max_seq_len_source = 0\n",
    "max_seq_len_target = 0\n",
    "\n",
    "for data in raw_train_dataset[\"translation\"]:\n",
    "    enc_ids = toknizer_en.encode(data[\"en\"]).ids\n",
    "    dec_ids = toknizer_my.encode(data[\"ms\"]).ids\n",
    "    max_seq_len_source = max(max_seq_len_source, len(enc_ids))\n",
    "    max_seq_len_target = max(max_seq_len_target, len(dec_ids))\n",
    "    \n",
    "print(f'max_seqlen_source: {max_seq_len_source}')   #530\n",
    "print(f'max_seqlen_target: {max_seq_len_target}')   #526\n",
    "\n",
    "# To simplify the training process, we'll just take single max_seq_len and add 20 to cover the additional length of tokens such as PAD, CLS, SEP in the sequence.\n",
    "max_seq_len = 550\n",
    "\n",
    "# Instantiate the EncodeRawDataset class and create the encoded train and validation-dataset.\n",
    "train_dataset = EncodeDataset(raw_train_dataset[\"translation\"], max_seq_len)\n",
    "val_dataset = EncodeDataset(raw_validate_dataset[\"translation\"], max_seq_len)\n",
    "\n",
    "# Creating DataLoader wrapper for both training and validation dataset. This dataloader will be used later stage during training and validation of our LLM model.\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 10, shuffle = True, generator=torch.device(\"cuda\"))\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = 1, shuffle = True, generator=torch.device(\"cuda\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba5ebba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmabadingLayer(nn.Module):\n",
    "    def __init__(self, d_model:int, vocab_size:int):\n",
    "        super().__init__()\n",
    "        self.d_model=d_model\n",
    "        self.embading=nn.Embedding(vocab_size,d_model)\n",
    "    def forward(self,input):\n",
    "        embading_output=self.embading(input)*math.sqrt(self.d_model)\n",
    "        return embading_output\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3461b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class positional_encoding(nn.Module):\n",
    "     def __init__(self, d_model:int, max_seq_len:int,dropout_rate:float):\n",
    "        super().__init__()\n",
    "        ##dropout to prevent overfiting\n",
    "        self.dropout=nn.Dropout(dropout_rate)\n",
    "        pe=torch.zeros(max_seq_len,d_model)\n",
    "        pos=torch.arange(0,max_seq_len,dtype=torch.float).unsqueeze(1)\n",
    "        #calc angles for sin and cos\n",
    "        div_term=torch.exp(torch.arange(0,d_model,2).float()** (-math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(pos * div_term)\n",
    "        pe[:, 1::2] = torch.cos(pos * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "     def forward(self, input_embdding):\n",
    "        input_embdding = input_embdding + (self.pe[:, :input_embdding.shape[1], :]).requires_grad_(False)   # to prevent from calculating gradient\n",
    "        return self.dropout(input_embdding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7243b134",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self,d_model:int,num_heads:int,dropout_rate:float):\n",
    "        super().__init__()\n",
    "        self.dropout=nn.Dropout(dropout_rate)\n",
    "        self.num_heads=num_heads\n",
    "        assert d_model %num_heads==0, \"d_model must be divisible by number of heads\"\n",
    "        self.d_k=d_model//num_heads\n",
    "        self.W_q=nn.Linear(d_model,d_model,bias=False)\n",
    "        self.W_k=nn.Linear(d_model,d_model,bias=False)\n",
    "        self.W_v=nn.Linear(d_model,d_model,bias=False)\n",
    "        self.W_o=nn.Linear(d_model,d_model,bias=False)\n",
    "\n",
    "    def Forward(self,q,k,v,encoder_mask):\n",
    "        query=self.W_q(q)\n",
    "        key=self.W_k(k)\n",
    "        value=self.W_v(v)\n",
    "        query=query.view(query.shape[0],query.shape[1],self.num_heads,self.d_k).transpose(1,2)\n",
    "        key = key.view(key.shape[0], key.shape[1], self.num_heads ,self.d_k).transpose(1,2)\n",
    "        value = value.view(value.shape[0], value.shape[1], self.num_heads ,self.d_k).transpose(1,2)\n",
    "        attention_score = (query @ key.transpose(-2,-1))/math.sqrt(self.d_k)\n",
    "\n",
    "        if encoder_mask is not None:\n",
    "            attention_score.masked_fill_(encoder_mask==0,-1e9)\n",
    "        attention_score=attention_score.softmax(dim=-1)\n",
    "        if self.dropout is not None:\n",
    "            attention_score=self.dropout(attention_score)\n",
    "\n",
    "\n",
    "        attention_output=attention_score @ value\n",
    "\n",
    "        attention_output=attention_output.transpose(1,2).contiguous().view(attention_output.shape[0], -1, self.num_heads * self.d_k) \n",
    "\n",
    "        multihead_output=self.W_o(attention_output)\n",
    "\n",
    "        return multihead_output       \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b683c21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
